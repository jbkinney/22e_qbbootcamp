{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers to exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:49:22.564773Z",
     "start_time": "2021-09-01T12:49:21.800789Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the usual stuff first\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "%matplotlib inline\n",
    "\n",
    "# We'll need this too\n",
    "import logomaker\n",
    "import os.path \n",
    "from scipy.signal import convolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This course will include a variety of exercises to increase your Python skills. Note that the knowledge needed to complete each exercise will NOT necessarily have been presented or discussed. If you find yourself at sea, **the first thing you should do is Google your question.** This is how 99% of programming is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1_introduction.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E1.1**: Create a markdown cell containing a bulleted list, a numbred list, and a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# Answer\n",
    "\n",
    "Bulleted list:\n",
    "- item A\n",
    "- item B\n",
    "- item C\n",
    "\n",
    "Numbered list:\n",
    "1. item A\n",
    "1. item B\n",
    "1. item C\n",
    "\n",
    "Table:\n",
    "\n",
    "| 1 | 2 | 3 |\n",
    "| - | - | - |\n",
    "| a | b | c |\n",
    "| d | e | f |\n",
    "| g | h | i |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E1.2**: Plot $y = x^2$ and $y = e^x$ on the same plot, with $x$ ranging from -3 to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:40:58.983871Z",
     "start_time": "2021-09-01T12:40:58.870263Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "x = np.arange(-3,3,0.01)\n",
    "y1 = x**2                \n",
    "y2 = np.exp(x)                \n",
    "plt.plot(x, y1)\n",
    "plt.plot(x, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E1.3**: Using the command line, print the first 100 lines of the file `data/old_BindingSiteSet.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T13:27:41.168405Z",
     "start_time": "2021-09-01T13:27:41.038313Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "!head -n 100 old_BindingSiteSet.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2_datatypes.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the DNA sequence of the multiple cloning site (MCS) on the plasmid [pcDNA5](https://www.addgene.org/vector-database/2132/), a popular vector for mammalian gene expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:41:01.723903Z",
     "start_time": "2021-09-01T12:41:01.719516Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note how to define a long string over multiple lines\n",
    "mcs_seq = 'GAGACCCAAGCTGGCTAGCGTTTAAACTTAAGCTTGGTACCGAGCTCGGATCCACTA' \\\n",
    "          'GTCCAGTGTGGTGGAATTCTGCAGATATCCAGCACAGTGGCGGCCGCTCGAGTCTAG' \\\n",
    "          'AGGGCCCGTTTAAACCCGCTGATCAGCCT'\n",
    "print(mcs_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E2.1**: Does this MCS contain a restriction site for NheI (GCTAGC)? How about for MscI (TGGCCA)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:41:02.165751Z",
     "start_time": "2021-09-01T12:41:02.160983Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "\n",
    "site_NheI = 'GCTAGC'\n",
    "site_MscI = 'TGGCCA'\n",
    "\n",
    "print('NheI: ', site_NheI in mcs_seq)\n",
    "print('MscI: ', site_MscI in mcs_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E2.2**: Using the string method `.find()`, find the location(s) of the above restriction sites within the MCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:41:02.556459Z",
     "start_time": "2021-09-01T12:41:02.551700Z"
    }
   },
   "outputs": [],
   "source": [
    "# find site\n",
    "site_start = mcs_seq.find(site_NheI)\n",
    "print('site starts at position %d'%site_start)\n",
    "\n",
    "# check\n",
    "site_stop = site_start + len(site_NheI)\n",
    "print('found site: ', mcs_seq[site_start:site_stop])\n",
    "print('NheI site : ', site_NheI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E2.3**: Using the string method `.replace()`, compute the RNA sequence transcribed from the GFP gene sequence (given below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:41:03.196244Z",
     "start_time": "2021-09-01T12:41:03.190753Z"
    }
   },
   "outputs": [],
   "source": [
    "gfp_seq = 'ATGAGTAAAGGAGAAGAACTTTTCACTGGAGTTGTCCCAATTCTTGTTGAATTAGATGGTGATG' \\\n",
    "          'TTAATGGGCACAAATTTTCTGTCAGTGGAGAGGGTGAAGGTGATGCAACATACGGAAAACTTAC' \\\n",
    "          'CCTTAAATTTATTTGCACTACTGGAAAACTACCTGTTCCATGGCCAACACTTGTCACTACTTTC' \\\n",
    "          'GCGTATGGTCTTCAATGCTTTGCGAGATACCCAGATCATATGAAACAGCATGACTTTTTCAAGA' \\\n",
    "          'GTGCCATGCCCGAAGGTTATGTACAGGAAAGAACTATATTTTTCAAAGATGACGGGAACTACAA' \\\n",
    "          'GACACGTGCTGAAGTCAAGTTTGAAGGTGATACCCTTGTTAATAGAATCGAGTTAAAAGGTATT' \\\n",
    "          'GATTTTAAAGAAGATGGAAACATTCTTGGACACAAATTGGAATACAACTATAACTCACACAATG' \\\n",
    "          'TATACATCATGGCAGACAAACAAAAGAATGGAATCAAAGTTAACTTCAAAATTAGACACAACAT' \\\n",
    "          'TGAAGATGGAAGCGTTCAACTAGCAGACCATTATCAACAAAATACTCCAATTGGCGATGGCCCT' \\\n",
    "          'GTCCTTTTACCAGACAACCATTACCTGTCCACACAATCTGCCCTTTCGAAAGATCCCAACGAAA' \\\n",
    "          'AGAGAGACCACATGGTCCTTCTTGAGTTTGTAACAGCTGCTGGGATTACACATGGCATGGATGA' \\\n",
    "          'ACTATACAAATAA'\n",
    "\n",
    "# Answer here\n",
    "gfp_rna = gfp_seq.replace('T','U')\n",
    "gfp_rna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E2.4**: Create a dictionary called `rc_dict` that maps DNA bases to their complementary bases. I.e., A -> T, C -> G, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:41:03.986602Z",
     "start_time": "2021-09-01T12:41:03.979731Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "rc_dict = {'A':'T', 'C':'G', 'G':'C', 'T':'A'}\n",
    "\n",
    "# For example:\n",
    "rc_dict['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:41:04.344965Z",
     "start_time": "2021-09-01T12:41:04.340501Z"
    }
   },
   "outputs": [],
   "source": [
    "# To compute the reverse complement, we need to create a 'translation table',\n",
    "# which is also a dictionary, but takes numerical ascii values as keys\n",
    "# instead of strings\n",
    "rc_table = str.maketrans(rc_dict)\n",
    "rc_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E2.5**: By passing `rc_table` to the string method `.translate()`, then using indexing with a step of -1, compute the reverse complement of the MCS sequence given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:41:05.387313Z",
     "start_time": "2021-09-01T12:41:05.383330Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute reverse complement\n",
    "mcs_seq_rc = mcs_seq.translate(rc_table)[::-1]\n",
    "\n",
    "# Print forward and RC sequences\n",
    "print('FW:', mcs_seq)\n",
    "print('RC:', mcs_seq_rc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E2.6**: We have not yet discussed sets. Using Google, figure out what `set` objects are and explain what they represent. In particular, explain why Python evaluates {2,3,3} < {1,2,3} as True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:41:06.219050Z",
     "start_time": "2021-09-01T12:41:06.215394Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sets are like lists, but the elements therein don't have a specific order.\n",
    "# Moreover, each element can occur at most once. \n",
    "# So {2,3,3} and {2,3} are the same set. To see this:\n",
    "print('{2,3,3} == {2,3} is %s.'%({2,3,3} == {2,3}))\n",
    "\n",
    "# The '<' sign is interpreted as Python as 'is subset'. Because\n",
    "# {2,3} is a subset of {1,2,3}, this evaluates to true\n",
    "print('{2,3} < {1,2,3} is %s.'%({2,3} < {1,2,3}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3_flowcontrol.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before there were calculators, people had to compute numbers like $\\pi$ by hand. This was done by deriving an infinite series expression, then hand-computing the first $N$ terms using standard arithmetic. One way of computing $\\pi$ was the **Leibnitz series**:\n",
    "\n",
    "$$\\pi = 4 \\left(1 - \\frac{1}{3} + \\frac{1}{5} - \\frac{1}{7} + \\cdots \\right) = \\sum_{n=0}^\\infty 4 \\frac{(-1)^n}{2n+1}$$\n",
    "\n",
    "A different way of computing $\\pi$ was the **Madhava series**:\n",
    "\n",
    "$$ \\pi = \\sqrt{12} \\left( 1 - \\frac{1}{3 \\cdot 3} + \\frac{1}{5 \\cdot 3^2}  - \\frac{1}{7 \\cdot 3^3}  + \\cdots \\right) = \\sum_{n=0}^\\infty \\sqrt{12} \\frac{(-1)^n}{(2n+1)\\cdot 3^n} $$\n",
    "\n",
    "We will compare the accuracies of these series in two different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E3.1**: Using a `for` loop, estimate $\\pi$ using the first $10$ terms in both the Liebnitz and Madhava series. Which estimate is more accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:41:07.269963Z",
     "start_time": "2021-09-01T12:41:07.261018Z"
    }
   },
   "outputs": [],
   "source": [
    "# Answer \n",
    "\n",
    "# Initialize both estimates of pi to zero\n",
    "pi_L = 0\n",
    "pi_M = 0\n",
    "\n",
    "# Iterate over n, each time adding the next term to each approximation\n",
    "for n in range(10):\n",
    "    pi_L += 4 * (-1)**n / (2*n + 1)\n",
    "    pi_M += np.sqrt(12) * (-1)**n / ((2*n+1) * 3**n)\n",
    "    \n",
    "# Print the results\n",
    "print('pi_L = %.15f'%pi_L)\n",
    "print('pi_M = %.15f'%pi_M)\n",
    "print('pi   = %.15f'%np.pi)\n",
    "print('The Madhava series is far more accurate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E3.2**: Write a function that computes the Leibnitz series for $\\pi$ to a specified number of terms. Include a docstring and checks to make sure the input is sane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:41:07.800220Z",
     "start_time": "2021-09-01T12:41:07.790926Z"
    }
   },
   "outputs": [],
   "source": [
    "# Write function here \n",
    "\n",
    "def pi_leibnitz(N):\n",
    "    \"\"\"\n",
    "    Computes the Liebnitz series for pi to N terms. \n",
    "    N must be an int >= 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check input\n",
    "    assert isinstance(N, int), 'N must be an integer'\n",
    "    assert N >= 0, 'N must be positive'\n",
    "    \n",
    "    # Compute terms\n",
    "    ns = np.arange(N)\n",
    "    terms = 4*((-1)**ns / (2*ns+1))\n",
    "    approx = terms.sum()\n",
    "    \n",
    "    # Return estimte to user\n",
    "    return approx\n",
    "\n",
    "# To check that this is working\n",
    "for N in [1, 10, 100, 1000]:\n",
    "    print('pi_leibnitz(%d) = %.10f'%(N,pi_leibnitz(N)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:41:08.018447Z",
     "start_time": "2021-09-01T12:41:07.971551Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check that the docstring works\n",
    "pi_leibnitz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:41:08.527270Z",
     "start_time": "2021-09-01T12:41:08.410019Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check that crazy input is caught\n",
    "pi_leibnitz(.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4_tfanalysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:53:15.251902Z",
     "start_time": "2021-09-01T12:53:15.225289Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cells in 4_tfanalysis.ipynb\n",
    "\n",
    "# Load dataframe\n",
    "df = pd.read_csv(\"old_BindingSiteSet.txt\", sep='\\t', comment='#',\n",
    "                 header=None, usecols=[1,11], names=['tf','site']).dropna()\n",
    "\n",
    "# Choose a TF\n",
    "tf = 'CRP'\n",
    "\n",
    "# Flag which rows in the dataframe have the correct TF name\n",
    "flags = (df['tf']==tf)\n",
    "\n",
    "# Grab those rows. To be safe use copy() to make sure that, if we\n",
    "# alter tf_df, df itself doesn't change\n",
    "tf_df = df[flags].copy()\n",
    "\n",
    "# Get list of capitalized sites and replace the 'site' column with this\n",
    "capitalized_sites = [site.upper() for site in tf_df['site']]\n",
    "tf_df['site'] = capitalized_sites\n",
    "\n",
    "# Compute the length of each site and record this in a 'length' column\n",
    "site_lengths = [len(site) for site in tf_df['site']]\n",
    "tf_df['length'] = site_lengths\n",
    "\n",
    "# preview dataframe\n",
    "tf_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E4.1.** Extract the `length` column of `tf_df` as a Series object, then use the `value_counts()` method to get a new Series object that lists number of times each length occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:53:17.009949Z",
     "start_time": "2021-09-01T12:53:16.999473Z"
    }
   },
   "outputs": [],
   "source": [
    "vc_series = tf_df['length'].value_counts()\n",
    "vc_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E4.2.** Apparently there are sites of a bunch of different lengths. Use the ```idxmax()``` method on the result above to determine which binding site length is most common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:53:20.063750Z",
     "start_time": "2021-09-01T12:53:20.057287Z"
    }
   },
   "outputs": [],
   "source": [
    "target_length = vc_series.idxmax()\n",
    "target_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E4.3.** Remove rows from `tf_df` that do not correspond to the most common length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:53:21.807310Z",
     "start_time": "2021-09-01T12:53:21.802898Z"
    }
   },
   "outputs": [],
   "source": [
    "flags = (tf_df['length'] == target_length)\n",
    "tf_df = tf_df[flags]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E4.4.** Counts logos shown above aren't what people use in publications. Rather, they typically use \"information\" logos, like the one shown earlier. By making use of the keyword argument  `to_type='information'` in the function `logomaker.alignment_to_matrix()`, create a CRP information logo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:53:24.837128Z",
     "start_time": "2021-09-01T12:53:24.328065Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the 'site' column from tf_df\n",
    "sites = tf_df['site']\n",
    "\n",
    "# Compute information matrix from this list of sites\n",
    "infomation_mat = logomaker.alignment_to_matrix(sites, to_type='information')\n",
    "\n",
    "# Visualize information matrix as a sequence logo\n",
    "logomaker.Logo(infomation_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E4.4.** Again using the `value_counts()` method, determine how many binding sites there are for each transcription factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:53:31.124847Z",
     "start_time": "2021-09-01T12:53:31.115680Z"
    }
   },
   "outputs": [],
   "source": [
    "df['tf'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E4.5.** Fill out the function below so that the user can pass the name of any TF and get list of aligned sites back. Test that it works, e.g. on `tf='FNR'`, by getting a list of sites and making an information logo. Also test that it fails when it is supposed to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:53:38.641565Z",
     "start_time": "2021-09-01T12:53:38.631243Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's turn this into a function \n",
    "def get_tf_sites(tf):\n",
    "    \"\"\"\n",
    "    Returns a list of sites for a specified transcription factor.\n",
    "    \"\"\"\n",
    "   \n",
    "    # # Load database\n",
    "    df = pd.read_csv(\"old_BindingSiteSet.txt\", \n",
    "                     sep='\\t', \n",
    "                     comment='#',\n",
    "                     header=None, \n",
    "                     usecols=[1,11], \n",
    "                     names=['tf','site'])\n",
    "    \n",
    "    # Make sure tf is a string\n",
    "    assert isinstance(tf, str), 'tf = %s is not a string'%repr(tf)\n",
    "    \n",
    "    # Make sure tf is actually in df['tf']\n",
    "    assert tf in df['tf'].values, 'tf = %s is not in database.'%tf\n",
    "    \n",
    "    # Flag which rows in the dataframe have the correct TF name\n",
    "    flags = (df['tf']==tf)\n",
    "\n",
    "    # Grab those rows. To be safe use copy() to make sure that, if we\n",
    "    # alter tf_df, df itself doesn't change\n",
    "    tf_df = df[flags].copy()\n",
    "    \n",
    "    # Remove rows with missing values\n",
    "    tf_df.dropna(inplace=True)\n",
    "\n",
    "    # Get list of capitalized sites and replace the 'site' column with this\n",
    "    capitalized_sites = [site.upper() for site in tf_df['site']]\n",
    "    tf_df['site'] = capitalized_sites\n",
    "\n",
    "    # Compute the length of each site and record this in a 'length' column\n",
    "    site_lengths = [len(site) for site in tf_df['site']]\n",
    "    tf_df['length'] = site_lengths\n",
    "    \n",
    "    # Use the mode() method to compute the most common binding site length\n",
    "    length_mode = tf_df['length'].mode()[0]\n",
    "\n",
    "    # Flag rows having sites of the chosen length\n",
    "    flags = (tf_df['length']==length_mode)\n",
    "\n",
    "    # Only keep these rows\n",
    "    tf_df = tf_df[flags]\n",
    "    \n",
    "    # Get sequence alignment and return it\n",
    "    return tf_df['site']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:53:45.237332Z",
     "start_time": "2021-09-01T12:53:44.723138Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now test that it works\n",
    "sites = get_tf_sites('CRP')\n",
    "info_mat = logomaker.alignment_to_matrix(sites, to_type='information')\n",
    "logomaker.Logo(info_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:53:46.015847Z",
     "start_time": "2021-09-01T12:53:45.928826Z"
    }
   },
   "outputs": [],
   "source": [
    "# And test that it fails when its supposed to\n",
    "sites = get_tf_sites('X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:53:47.562030Z",
     "start_time": "2021-09-01T12:53:47.536190Z"
    }
   },
   "outputs": [],
   "source": [
    "# And test that it fails when its supposed to\n",
    "sites = get_tf_sites(-1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5_dnareplication.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:33:43.199116Z",
     "start_time": "2021-09-01T12:33:43.187753Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def load_and_smooth_profile(file_name, chrom_we_want, window_bp=6000):\n",
    "    \"\"\"\n",
    "    Load a smooth a replication profile.\n",
    "    \n",
    "    Arguments:\n",
    "        file_name -- name of a bed file containing the data\n",
    "        chrom_we_want -- chromosome name in Roman numerals: chrI, ..., chrXVI\n",
    "        window_bp -- length of smoothing window in bp\n",
    "    \n",
    "    Returns:\n",
    "        centers -- location of bin centers along the chromosome\n",
    "        smooth_reads -- smoothed number of reads in each bin\n",
    "    \"\"\"\n",
    "   \n",
    "    # Check validity of file\n",
    "    assert isinstance(file_name,str), 'file_name is not a string.'\n",
    "    assert os.path.isfile(file_name), 'file %s does not exist'%file_name\n",
    "    \n",
    "    # Read file into dataframe \n",
    "    df = pd.read_csv(file_name,  \n",
    "                 names=['chromosome','start','stop','reads'], \n",
    "                 delim_whitespace=True, \n",
    "                 skiprows=2)\n",
    "    \n",
    "    # Check validity of chromosome\n",
    "    assert isinstance(chrom_we_want, str), 'chrom_we_want is not a string'\n",
    "    assert chrom_we_want in set(df['chromosome']), \\\n",
    "        'chrom_we_want value %s not found in data frame.'%chrom_we_want\n",
    "        \n",
    "    # Check validity of window_bp\n",
    "    assert isinstance(window_bp, int), \"window_bp is not an integer.\"\n",
    "    assert window_bp > 0, \"nonpositive window_bp value of %d\"%window_bp\n",
    "    \n",
    "    # Choose rows to look at\n",
    "    indices = (df['chromosome']==chrom_we_want)\n",
    "    \n",
    "    # Extract read_lenght, num_reads and centers\n",
    "    chr_df = df[indices]\n",
    "    num_reads = chr_df['reads']\n",
    "    starts = chr_df['start']\n",
    "    stops = chr_df['stop']\n",
    "    centers = 0.5*(starts + stops)\n",
    "    \n",
    "    # Create convolution window\n",
    "    read_length = df.loc[0,'stop'] - df.loc[0,'start'] + 1\n",
    "    window_size = window_bp//read_length\n",
    "    window = np.ones(window_size)/window_size\n",
    "    \n",
    "    # Smooth read counts\n",
    "    smooth_reads = convolve(num_reads,window,'same')\n",
    "    \n",
    "    # Now return results\n",
    "    return centers, smooth_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:33:44.823524Z",
     "start_time": "2021-09-01T12:33:44.811951Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_profile(centers, \n",
    "                 smooth_reads,  \n",
    "                 title='', \n",
    "                 kbspacing=200, \n",
    "                 color=[0, .5, 1]):\n",
    "    \"\"\"\n",
    "    Plot a replication profile\n",
    "    \n",
    "    Arguments:\n",
    "        centers -- numpy array of bin locations\n",
    "        smooth_reads -- numpy array of smoothed read counts; same length as centers\n",
    "        title -- title for plot\n",
    "        kbspacing -- tick mark spaking in kilobases\n",
    "        color -- color of plot\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(centers)==len(smooth_reads), \"centers and smooth_reads are not the same length.\"\n",
    "    assert isinstance(title,str), \"title is not a string\"\n",
    "    assert isinstance(kbspacing,int), \"kbspacing is not an int\"\n",
    "    assert kbspacing > 0, \"nonpositive kbspacing value of %d\"%kbspacing\n",
    "    \n",
    "    # Easier to discuss genomic positions in kb\n",
    "    kb = 1E3\n",
    "    x = centers/kb\n",
    "    L = max(x)\n",
    "    \n",
    "    label_size = 16\n",
    "    \n",
    "    # Plot\n",
    "    plt.fill_between(x, smooth_reads, color=color)\n",
    "\n",
    "    # Place tick marks on x axis ever 200 kb\n",
    "    plt.xticks(np.arange(0,L,kbspacing), fontsize=label_size)\n",
    "    \n",
    "    # Fit plot to precisely the width of the chromosome\n",
    "    plt.xlim([min(x), max(x)])\n",
    "    \n",
    "    # Turn off box\n",
    "    plt.box(False)\n",
    "    \n",
    "    # No need to show ticks on the y axes\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # Add some text annotation, telling the user\n",
    "    plt.title(title, fontsize=label_size)\n",
    "    plt.xlabel('position (in kb)', fontsize=label_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E5.1.** Using `load_and_smooth_profile()` and `plot_profile()`, fill in code in the subsequent cell to plot four replication profiles in a single figure, using the specified colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:33:57.101989Z",
     "start_time": "2021-09-01T12:33:56.103512Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot 4 replication profiles\n",
    "plt.figure(figsize=[20,5])\n",
    "\n",
    "# Chromosome to focus on\n",
    "chrom_we_want = 'chrII'\n",
    "\n",
    "# Names of samples\n",
    "samples = ['A','B','C','D']\n",
    "\n",
    "# Define colors\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:purple']\n",
    "\n",
    "# Look over each sample\n",
    "for i, (sample, color) in enumerate(zip(samples, colors)):\n",
    "\n",
    "    ### Answer here -- Specify file name, then load centers and smoothed counts\n",
    "    file_name = '%s1.pileup.bed'%sample  \n",
    "    ctrs, rds = load_and_smooth_profile(file_name, chrom_we_want)\n",
    "    \n",
    "    # Create axes on which to plot\n",
    "    plt.subplot(2,2,i+1)\n",
    "    \n",
    "    ### Answer here -- Plot profile here\n",
    "    title = 'sample %s, %s'%(sample, chrom_we_want)\n",
    "    plot_profile(ctrs, rds, title=title, kbspacing=100, color=color)\n",
    "\n",
    "# Fix layout\n",
    "plt.tight_layout(w_pad=5, h_pad=2)\n",
    "\n",
    "# Save \n",
    "file_name = '5_dnareplication_2.png'\n",
    "plt.savefig(file_name)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Open figure in another applicaiton\n",
    "!open $file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 6_matplotlib.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:34:02.407418Z",
     "start_time": "2021-09-01T12:34:02.395311Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set seaborn plotting style style\n",
    "sns.set_style('ticks')\n",
    "\n",
    "# Load Iris data \n",
    "df = sns.load_dataset('iris')\n",
    "\n",
    "# Define a function to add some jitter to each data point\n",
    "def jitter(vec, sigma):\n",
    "    \"Adds a normal random number with std sigma to each entry of the np.array vec\"\n",
    "    return vec + sigma*np.random.randn(len(vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E6.1** By specifying \"sharey=True\" and \"sharex=True\" in plt.subplots(), and by conditioning ax.set_ylabel() on i==1, make all three panels use the same y-axis. You might also want to increase the spacing between plots by specifying \"w_pad=3\" in tight_layout()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-01T12:34:04.254478Z",
     "start_time": "2021-09-01T12:34:04.052218Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a figure on which to draw this\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=[8,3], sharey=True, sharex=True)\n",
    "\n",
    "# Define colors for dots\n",
    "colors = ['C0','C1','C2']\n",
    "\n",
    "# Define the amount of jitter\n",
    "sigma = .05\n",
    "\n",
    "# Iterate over species\n",
    "species = df['species'].unique()\n",
    "for i, s in enumerate(species):\n",
    "    \n",
    "     # Get rows specific to species\n",
    "    rows = df['species']==s\n",
    "\n",
    "    # Extract lengths and widths\n",
    "    lengths = df.loc[rows, 'sepal_length'].values\n",
    "    widths = df.loc[rows, 'sepal_width'].values\n",
    "    \n",
    "    # Add jitter\n",
    "    lengths_j = jitter(lengths, 0.05)\n",
    "    widths_j = jitter(widths, 0.05)\n",
    "    \n",
    "    # Set ax\n",
    "    ax = axs[i]\n",
    "    \n",
    "    # Draw points\n",
    "    ax.scatter(x=widths_j,              \n",
    "               y=lengths_j, \n",
    "               alpha=.5,             # Opacity   \n",
    "               marker='o',           # Marker shape\n",
    "               s=50,                 # Marker size\n",
    "               color=colors[i],      # Marker color\n",
    "               linewidths=0)         # Removes boundary from marker\n",
    "\n",
    "    # Set the x and y labels\n",
    "    ax.set_xlabel('sepal width (cm)', fontsize=10)\n",
    "    \n",
    "    if i==0:\n",
    "        ax.set_ylabel('sepal length (cm)', fontsize=10)\n",
    "    \n",
    "    # Make a title\n",
    "    ax.set_title('species: %s'%s, fontsize=10)\n",
    "    \n",
    "# Make sure labels don't get pushed off plot\n",
    "plt.tight_layout(w_pad=3)\n",
    "\n",
    "# Label panels\n",
    "fig.text(x=.01, y=.99, s='(A)', horizontalalignment='left', verticalalignment='top', fontsize=12)\n",
    "fig.text(x=.35, y=.99, s='(B)', horizontalalignment='left', verticalalignment='top', fontsize=12)\n",
    "fig.text(x=.67, y=.99, s='(C)', horizontalalignment='left', verticalalignment='top', fontsize=12)\n",
    "\n",
    "# Save figure\n",
    "file_name = '6_matplotlib_4.pdf'\n",
    "fig.savefig(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
